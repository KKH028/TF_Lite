{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23569,"status":"ok","timestamp":1671419114220,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"-BK5ZQY5zaeY","outputId":"8656c64c-4b34-4705-ac1e-7b5a6a5d6008"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/google_drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/google_drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"27DYfNKMzgqv"},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OpGlzsvzmVP"},"outputs":[],"source":["!pip install -U \"tensorflow>=2.5\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m-rxniuY2Uc9"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6rEbMg-zx_Q"},"outputs":[],"source":["import os\n","import pathlib\n","\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","import io\n","import scipy.misc\n","import numpy as np\n","from six import BytesIO\n","from PIL import Image, ImageDraw, ImageFont\n","from six.moves.urllib.request import urlopen\n","\n","\n","# import tensorflow_hub as hub\n","\n","tf.get_logger().setLevel('ERROR')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9vJzHKphzz7f"},"outputs":[],"source":["import re\n","from shutil import copyfile\n","import argparse\n","import math\n","import random"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VCjwoQZFz1z_"},"outputs":[],"source":["import numpy as np\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')   # Suppress Matplotlib warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39850,"status":"ok","timestamp":1671419472826,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"vIKefw83W_vb","outputId":"b1fa195c-9cf9-4c48-a9f8-7ac89b5f0b85"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'models'...\n","remote: Enumerating objects: 79836, done.\u001b[K\n","remote: Counting objects: 100% (12/12), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 79836 (delta 5), reused 1 (delta 0), pack-reused 79824\u001b[K\n","Receiving objects: 100% (79836/79836), 594.01 MiB | 16.48 MiB/s, done.\n","Resolving deltas: 100% (56848/56848), done.\n"]}],"source":["if \"models\" in pathlib.Path.cwd().parts:\n","  while \"models\" in pathlib.Path.cwd().parts:\n","    os.chdir('..')\n","elif not pathlib.Path('models').exists():\n","  !git clone https://github.com/tensorflow/models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVtOwArwzQ3V"},"outputs":[],"source":["%%bash\n","sudo apt install -y protobuf-compiler\n","cd /content/models/research/\n","protoc object_detection/protos/*.proto --python_out=.\n","cd /content\n","git clone https://github.com/cocodataset/cocoapi.git\n","cd /content/cocoapi/PythonAPI\n","make\n","cp -r pycocotools /content/models/research/\n","cd /content/models/research/\n","cp object_detection/packages/tf2/setup.py .\n","python -m pip install .\n","cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r7XmAPDDIqcP"},"outputs":[],"source":["!python /content/models/research/object_detection/builders/model_builder_tf2_test.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ES0wILdrf2zw"},"outputs":[],"source":["output_directory = '/content/tf_lite'"]},{"cell_type":"code","source":["!rm -r \"/content/tf_lite\""],"metadata":{"id":"9e3cFh-2D4DB"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FmS8QGwtf7B4"},"outputs":[],"source":["!python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n","--trained_checkpoint_dir=\"/content/google_drive/MyDrive/Tensorflow_OD_API/efficientdet_d0_tflite/workspace/my_model1/checkpoint\" \\\n","--output_directory='/content/tf_lite' \\\n","--pipeline_config_path=\"/content/google_drive/MyDrive/Tensorflow_OD_API/efficientdet_d0_tflite/workspace/my_model1/pipeline.config\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tMEqSWV7w7m7"},"outputs":[],"source":["# !python /content/models/research/object_detection/export_tflite_graph_tf2.py \\\n","# --trained_checkpoint_dir=\"/content/google_drive/MyDrive/Tensorflow_OD_API/EfficientDet_D1_640x640/workspace/training_demo/exported-models/saved_efficientDet_D1/checkpoint\" \\\n","# --output_directory='/content/tf_lite2' \\\n","# --pipeline_config_path=\"/content/google_drive/MyDrive/Tensorflow_OD_API/EfficientDet_D1_640x640/workspace/training_demo/exported-models/saved_efficientDet_D1/pipeline.config\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":560,"status":"ok","timestamp":1671419694361,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"V-z5uWuBiomZ","outputId":"b5e25b7f-7f22-48d5-c5fe-41cd9e715c06"},"outputs":[{"name":"stdout","output_type":"stream","text":["total 7.9M\n","drwxr-xr-x 4 root root 4.0K Dec 19 03:14 .\n","drwxr-xr-x 3 root root 4.0K Dec 19 03:14 ..\n","drwxr-xr-x 2 root root 4.0K Dec 19 03:14 assets\n","-rw-r--r-- 1 root root   57 Dec 19 03:14 fingerprint.pb\n","-rw-r--r-- 1 root root 7.9M Dec 19 03:14 saved_model.pb\n","drwxr-xr-x 2 root root 4.0K Dec 19 03:14 variables\n"]}],"source":["!ls -lah /content/tf_lite/saved_model/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20815,"status":"ok","timestamp":1671431261771,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"4sbwX2-Ui7Yx","outputId":"4c473134-d04e-4f05-d264-a52f2fdc770f"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-12-19 06:27:21.963618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-12-19 06:27:21.963719: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n","2022-12-19 06:27:21.963740: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","2022-12-19 06:27:25.043643: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-12-19 06:27:34.173680: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:362] Ignored output_format.\n","2022-12-19 06:27:34.173742: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:365] Ignored drop_control_dependency.\n"]}],"source":["!tflite_convert --saved_model_dir=/content/tf_lite/saved_model/ --output_file=tf_lite/model.tflite"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":496,"status":"ok","timestamp":1671419745399,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"ckkqr4bIjQcJ","outputId":"b52d43ca-8e30-4ed5-9223-f991d3783407"},"outputs":[{"name":"stdout","output_type":"stream","text":["-rw-r--r-- 1 root root 195M Dec 19 03:15 tf_lite/model.tflite\n"]}],"source":["!ls -lah tf_lite/model.tflite"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TaFKTxPxjaCR"},"outputs":[],"source":["# based on https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/raspberry_pi/detect_picamera.py\n","\n","from PIL import Image, ImageDraw, ImageFont\n","import re, glob\n","from six import BytesIO\n","import numpy as np\n","%matplotlib inline\n","\n","def draw_image(image, results, size):\n","    result_size = len(results)\n","    for idx, obj in enumerate(results):\n","        # Prepare image for drawing\n","        draw = ImageDraw.Draw(image)\n","\n","        # Prepare boundary box\n","        xmin, ymin, xmax, ymax = obj['bounding_box']\n","        xmin = int(xmin * size[1])\n","        xmax = int(xmax * size[1])\n","        ymin = int(ymin * size[0])\n","        ymax = int(ymax * size[0])\n","\n","        # Draw rectangle to desired thickness\n","        for x in range( 0, 4 ):\n","            draw.rectangle((ymin, xmin, ymax, xmax), outline=(255, 255, 0), width=5)\n","\n","    displayImage = np.asarray( image )\n","    display(Image.fromarray(displayImage))\n","\n","def load_labels(path):\n","    \"\"\"Loads the labels file. Supports files with or without index numbers.\"\"\"\n","    with open(path, 'r', encoding='utf-8') as f:\n","        lines = f.readlines()\n","        labels = {}\n","        for row_number, content in enumerate(lines):\n","            pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\n","            if len(pair) == 2 and pair[0].strip().isdigit():\n","                labels[int(pair[0])] = pair[1].strip()\n","            else:\n","                labels[row_number] = pair[0].strip()\n","    return labels\n","\n","def set_input_tensor(interpreter, image):\n","    \"\"\"Sets the input tensor.\"\"\"\n","    tensor_index = interpreter.get_input_details()[0]['index']\n","    input_tensor = interpreter.tensor(tensor_index)()[0]\n","    input_tensor[:, :] = image\n","\n","\n","def get_output_tensor(interpreter, index):\n","    \"\"\"Returns the output tensor at the given index.\"\"\"\n","    output_details = interpreter.get_output_details()[index]\n","    tensor = np.squeeze(interpreter.get_tensor(output_details['index']))\n","    return tensor\n","\n","\n","def detect_objects(interpreter, image, threshold):\n","    \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\n","    set_input_tensor(interpreter, image)\n","    interpreter.invoke()\n","\n","    # Get all output details\n","    scores = get_output_tensor(interpreter, 0)   #0:scores\n","    boxes = get_output_tensor(interpreter, 1) #1:boxes\n","    count = int(get_output_tensor(interpreter, 2)) #2:count\n","    classes = get_output_tensor(interpreter, 3) #3:classes\n","    # what = get_output_tensor(interpreter, 4) #3:classes\n","    # count = int(get_output_tensor(interpreter, 3))\n","    print(\"boxes=\", boxes)\n","    print(\"classes=\", classes)\n","    print(\"scores=\", scores)\n","    print(\"count=\", count)\n","    # print(\"what=\", what)\n","\n","    results = []\n","    for i in range(count):\n","        if scores[i] >= threshold:\n","            result = {\n","                'bounding_box': boxes[i],\n","                'class_id': classes[i],\n","                'score': scores[i]\n","            }\n","            results.append(result)\n","    \n","    return results"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z3wj83Ymjcnp"},"outputs":[],"source":["interpreter = tf.lite.Interpreter(model_path=\"tf_lite/model.tflite\")\n","interpreter.allocate_tensors()\n","_, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1671420244204,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"p8XaCM4vv5qj","outputId":"a32139e3-b024-456f-dd16-2c6e0172fc63"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1671431277349,"user":{"displayName":"서성원","userId":"03248215396884205789"},"user_tz":-540},"id":"jIwcef0Sv8RT","outputId":"d2ff3c2f-7c48-4b51-a08e-f527175005c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 584\n","drwxr-xr-x 2 root root   4096 Dec 19 03:20 .\n","drwxr-xr-x 1 root root   4096 Dec 19 06:26 ..\n","-rw-r--r-- 1 root root 494356 Dec 19 03:20 abyssinian.jpg\n","-rw-r--r-- 1 root root  92353 Dec 19 03:20 Bulldog.jpg\n"]}],"source":["!ls -al /content/testimages/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3k9iyx8DjhBh"},"outputs":[],"source":["input_mean = 0\n","input_std = 1\n","\n","for i, image_path in enumerate(glob.glob('/content/testimages/*.jpg')):\n","  print(image_path)\n","  image = Image.open(image_path)\n","  image_pred = image.resize((input_width ,input_height), Image.ANTIALIAS)\n","  if interpreter.get_input_details()[0]['dtype'] == np.float32:\n","    image_pred = (np.float32(image_pred) - input_mean) / input_std\n","  results = detect_objects(interpreter, image_pred, 0.2)\n","  print(results)\n","\n","  draw_image(image, results, image.size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CDc0OTJW0KnG"},"outputs":[],"source":["from object_detection.utils import label_map_util"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GUi4_AaQ0QvU"},"outputs":[],"source":["_ODT_LABEL_MAP_PATH = '/content/google_drive/MyDrive/Tensorflow_OD_API/efficientdet_d0_tflite/workspace/my_model1/label_map.pbtxt'\n","_TFLITE_LABEL_PATH = \"/content/label_map.txt\"\n","\n","category_index = label_map_util.create_category_index_from_labelmap(\n","    _ODT_LABEL_MAP_PATH)\n","f = open(_TFLITE_LABEL_PATH, 'w')\n","for class_id in range(1, 38):   ###############\n","  if class_id not in category_index:\n","    f.write('???\\n')\n","    continue\n","  name = category_index[class_id]['name']\n","  f.write(name+'\\n')\n","f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FnejPKzh87sO"},"outputs":[],"source":["# !pip install tf-nightly -q"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6y2iQlOQ9Fj2"},"outputs":[],"source":["# !pip install tflite-support"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8jAysTKw-U8Y"},"outputs":[],"source":["!pip install tflite_support_nightly"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FBCLkW1jBrdo"},"outputs":[],"source":["# !pip install -U flatbuffers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H1Neee04_2QQ"},"outputs":[],"source":["# import flatbuffers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64zZP_820s88"},"outputs":[],"source":["from tflite_support.metadata_writers import object_detector\n","from tflite_support.metadata_writers import writer_utils\n","\n","ObjectDetectorWriter = object_detector.MetadataWriter"]},{"cell_type":"code","source":["!ls -al /content/tf_lite/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pW5XjOpnsC_p","executionInfo":{"status":"ok","timestamp":1671431321942,"user_tz":-540,"elapsed":463,"user":{"displayName":"서성원","userId":"03248215396884205789"}},"outputId":"bae24cea-dfdf-45f8-f4f2-4057ea5da344"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["total 198976\n","drwxr-xr-x 3 root root      4096 Dec 19 03:15 .\n","drwxr-xr-x 1 root root      4096 Dec 19 06:26 ..\n","-rw-r--r-- 1 root root 203736792 Dec 19 06:27 model.tflite\n","drwxr-xr-x 4 root root      4096 Dec 19 06:27 saved_model\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0WlvqjVi_Wrg"},"outputs":[],"source":["_MODEL_PATH=\"/content/tf_lite/model.tflite\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1GlzHKr1lD0"},"outputs":[],"source":["_TFLITE_MODEL_WITH_METADATA_PATH = '/content/model_with_metadata.tflite'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AdVVyIWNAQe4"},"outputs":[],"source":["_TFLITE_LABEL_PATH=\"/content/label_map.txt\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BwLSkUZH1iF1"},"outputs":[],"source":["writer = ObjectDetectorWriter.create_for_inference(\n","    writer_utils.load_file(_MODEL_PATH), [127.5], [127.5],[_TFLITE_LABEL_PATH])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTT0F2eN1v_c"},"outputs":[],"source":["writer_utils.save_file(writer.populate(), _TFLITE_MODEL_WITH_METADATA_PATH)"]},{"cell_type":"code","source":["from tflite_support import metadata"],"metadata":{"id":"lsi_7jJZuFmJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["displayer = metadata.MetadataDisplayer.with_model_file(_TFLITE_MODEL_WITH_METADATA_PATH)"],"metadata":{"id":"8KIHAkVut-66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Metadata populated:\")\n","print(displayer.get_metadata_json())\n","print(\"Associated file(s) populated:\")\n","print(displayer.get_packed_associated_file_list())"],"metadata":{"id":"YEhSToHK2sQs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["displayer = metadata.MetadataDisplayer.with_model_file(\"/content/efficientdet-lite1.tflite\")"],"metadata":{"id":"Jg3rs6zazQir"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Metadata populated:\")\n","print(displayer.get_metadata_json())\n","print(\"Associated file(s) populated:\")\n","print(displayer.get_packed_associated_file_list())"],"metadata":{"id":"s89b1XT1uJ-T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import flatbuffers\n","import os\n","from tensorflow_lite_support.metadata import metadata_schema_py_generated as _metadata_fb\n","from tensorflow_lite_support.metadata.python import metadata as _metadata\n","from tensorflow_lite_support.metadata.python.metadata_writers import metadata_info\n","from tensorflow_lite_support.metadata.python.metadata_writers import metadata_writer\n","from tensorflow_lite_support.metadata.python.metadata_writers import writer_utils"],"metadata":{"id":"NXBQbkHgudq6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_meta = _metadata_fb.ModelMetadataT()"],"metadata":{"id":"Dp-qsgtxuY8J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_meta.name=\"efficientdet_d1_oxford_pet_detector\""],"metadata":{"id":"Q7d66EjtuhIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_meta.description = (\n","    \"Identify which of a known set of objects might be present and provide \"\n","    \"information about their positions within the given image or a video \"\n","    \"stream.\")"],"metadata":{"id":"81DteNP4urKK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"653xbKYKL-Ej"}},{"cell_type":"markdown","source":[],"metadata":{"id":"LF5C31HVL-j6"}},{"cell_type":"code","source":["# Creates input info.\n","input_meta = _metadata_fb.TensorMetadataT()\n","input_meta.name = \"image\"\n","input_meta.content = _metadata_fb.ContentT()\n","input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n","input_meta.content.contentProperties.colorSpace = (\n","    _metadata_fb.ColorSpaceType.RGB)\n","input_meta.content.contentPropertiesType = (\n","    _metadata_fb.ContentProperties.ImageProperties)\n","input_normalization = _metadata_fb.ProcessUnitT()\n","input_normalization.optionsType = (\n","    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n","input_normalization.options = _metadata_fb.NormalizationOptionsT()\n","input_normalization.options.mean = [127.5]\n","input_normalization.options.std = [127.5]\n","input_meta.processUnits = [input_normalization]\n","input_stats = _metadata_fb.StatsT()\n","input_stats.max = [255]\n","input_stats.min = [0]\n","input_meta.stats = input_stats"],"metadata":{"id":"wGx40UyCuvQi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creates outputs info.\n","output_location_meta = _metadata_fb.TensorMetadataT()\n","output_location_meta.name = \"location\"\n","output_location_meta.description = \"The locations of the detected boxes.\"\n","output_location_meta.content = _metadata_fb.ContentT()\n","output_location_meta.content.contentPropertiesType = (\n","    _metadata_fb.ContentProperties.BoundingBoxProperties)\n","output_location_meta.content.contentProperties = (\n","    _metadata_fb.BoundingBoxPropertiesT())\n","output_location_meta.content.contentProperties.index = [1, 0, 3, 2]\n","output_location_meta.content.contentProperties.type = (\n","    _metadata_fb.BoundingBoxType.BOUNDARIES)\n","output_location_meta.content.contentProperties.coordinateType = (\n","    _metadata_fb.CoordinateType.RATIO)\n","output_location_meta.content.range = _metadata_fb.ValueRangeT()\n","output_location_meta.content.range.min = 2\n","output_location_meta.content.range.max = 2"],"metadata":{"id":"T_hkXN3Au0ZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_class_meta = _metadata_fb.TensorMetadataT()\n","output_class_meta.name = \"category\"\n","output_class_meta.description = \"The categories of the detected boxes.\"\n","output_class_meta.content = _metadata_fb.ContentT()\n","output_class_meta.content.contentPropertiesType = (\n","    _metadata_fb.ContentProperties.FeatureProperties)\n","output_class_meta.content.contentProperties = (\n","    _metadata_fb.FeaturePropertiesT())\n","output_class_meta.content.range = _metadata_fb.ValueRangeT()\n","output_class_meta.content.range.min = 2\n","output_class_meta.content.range.max = 2\n","label_file = _metadata_fb.AssociatedFileT()\n","label_file.name = os.path.basename(\"label_map.txt\")\n","label_file.description = \"Label of objects that this model can recognize.\"\n","label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n","output_class_meta.associatedFiles = [label_file]"],"metadata":{"id":"Mtp6Fj12u3-6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_score_meta = _metadata_fb.TensorMetadataT()\n","output_score_meta.name = \"score\"\n","output_score_meta.description = \"The scores of the detected boxes.\"\n","output_score_meta.content = _metadata_fb.ContentT()\n","output_score_meta.content.contentPropertiesType = (\n","    _metadata_fb.ContentProperties.FeatureProperties)\n","output_score_meta.content.contentProperties = (\n","    _metadata_fb.FeaturePropertiesT())\n","output_score_meta.content.range = _metadata_fb.ValueRangeT()\n","output_score_meta.content.range.min = 2\n","output_score_meta.content.range.max = 2"],"metadata":{"id":"KQKF_UJRvGsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["output_number_meta = _metadata_fb.TensorMetadataT()\n","output_number_meta.name = \"number of detections\"\n","output_number_meta.description = \"The number of the detected boxes.\"\n","output_number_meta.content = _metadata_fb.ContentT()\n","output_number_meta.content.contentPropertiesType = (\n","    _metadata_fb.ContentProperties.FeatureProperties)\n","output_number_meta.content.contentProperties = (\n","    _metadata_fb.FeaturePropertiesT())\n"],"metadata":{"id":"JOTY4kIDvKIJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Creates subgraph info.\n","group = _metadata_fb.TensorGroupT()\n","group.name = \"detection result\"\n","group.tensorNames = [\n","    output_location_meta.name, output_class_meta.name,\n","    output_score_meta.name\n","]\n","subgraph = _metadata_fb.SubGraphMetadataT()\n","subgraph.inputTensorMetadata = [input_meta]\n","subgraph.outputTensorMetadata = [\n","    output_location_meta, output_class_meta, output_score_meta,\n","    output_number_meta\n","]\n","subgraph.outputTensorGroups = [group]\n","model_meta.subgraphMetadata = [subgraph]\n","\n","b = flatbuffers.Builder(0)\n","b.Finish(\n","    model_meta.Pack(b),\n","    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n","metadata_buf = b.Output()"],"metadata":{"id":"Qwr_jkDTvOY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["populator = _metadata.MetadataPopulator.with_model_file(\"/content/model_with_metadata.tflite\")\n","populator.load_metadata_buffer(metadata_buf)\n","# populator.load_associated_files([\"/content/label_map.txt\"])\n","populator.populate()"],"metadata":{"id":"MSl4sBpgLyeT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"IrLKf3yDuKWC"}},{"cell_type":"markdown","source":[],"metadata":{"id":"KQ55BK9ouK0C"}},{"cell_type":"code","source":["displayer = metadata.MetadataDisplayer.with_model_file(_TFLITE_MODEL_WITH_METADATA_PATH)\n","print(\"Metadata populated:\")\n","print(displayer.get_metadata_json())\n","print(\"Associated file(s) populated:\")\n","print(displayer.get_packed_associated_file_list())"],"metadata":{"id":"gvkLqAaDNGIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["displayer = _metadata.MetadataDisplayer.with_model_file(export_model_path)\n","export_json_file = os.path.join(FLAGS.export_directory,\n","                    os.path.splitext(model_basename)[0] + \".json\")\n","json_file = displayer.get_metadata_json()\n","# Optional: write out the metadata as a json file\n","with open(export_json_file, \"w\") as f:\n","  f.write(json_file)"],"metadata":{"id":"aVYdVtsCMnkT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["interpreter = tf.lite.Interpreter(model_path=\"/content/model_with_metadata.tflite\")\n","interpreter.allocate_tensors()\n","_, input_height, input_width, _ = interpreter.get_input_details()[0]['shape']"],"metadata":{"id":"5x-hn2D5tcHL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["input_mean = 0\n","input_std = 1\n","\n","for i, image_path in enumerate(glob.glob('/content/testimages/*.jpg')):\n","  print(image_path)\n","  image = Image.open(image_path)\n","  image_pred = image.resize((input_width ,input_height), Image.ANTIALIAS)\n","  print(np.float32(image_pred))\n","  print(\"*\" * 60)\n","  if interpreter.get_input_details()[0]['dtype'] == np.float32:\n","    image_pred = (np.float32(image_pred) - input_mean) / input_std\n","    print(image_pred)\n","  results = detect_objects(interpreter, image_pred, 0.2)\n","  print(results)\n","\n","  draw_image(image, results, image.size)"],"metadata":{"id":"93emsia6tkmh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MbLZWGasi8NC"},"source":[]},{"cell_type":"markdown","metadata":{"id":"Ntq-Nt97i70p"},"source":[]},{"cell_type":"markdown","metadata":{"id":"bivm6kVCocLx"},"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}